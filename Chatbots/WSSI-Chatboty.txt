Lab 1 - porozmawiaj z botem!
Krystian Kogut - 308128
Zad 1 
Według mojej opinii wszystkie wymienione poniżej zadania wymagają od człowieka pewnej inteligencji, która sama w sobie nie jest pojęciem jednoznacznym. W większości wymienionych przypadków wystarcza inteligencja definiowana jako zdolność rozwiązywania problemów, dostrzeganiem zależności bądź zdolności uczenia się, które są niezbędne do wykonania danych czynności. Koniec końców ciężko by było obliczać pochodne funkcji gdyby nie nasza inteligencja, którą definiuje się jako zdolność uczenia się (nauka o pochodnych) i rozwiązywania problemów (obliczania pochodnej). Mimo, iż niektóre z tych czynności wydają się łatwe, tak gdy zgłębimy dany temat dowiemy się, że zadania te mogą kryć więcej, niż może nam się wydawać. Wkracza wtedy inteligencja jako zdolność do przetwarzania informacji oraz poszukiwania, dowiadywania się i nauki pewnych zagadnień. 
Zad 2
W zakresie sztucznej inteligencji za mieszczące się możemy również uznać poniższe zagadnienia, aczkolwiek w tym temacie można znaleźć wiele nieścisłości i punktów spornych. 
Obecna sztuczna inteligencja potrafi większość z tych rzeczy, jednak często spotkać się można z przypadkami, gdy poleganie tylko na AI potrafi dać nam gorszy efekt niż samodzielne działanie człowieka. 
Jako przykład podać można kierowanie samochodem bądź tłumaczenie tekstu - mimo wielkich postępów w drugim przypadku nadal samo poleganie na systemach AI może wprowadzić w błąd osoby przyjeżdżające z zagranicy. Widoczne jest to zwłaszcza w krajach, gdzie język jest sam w sobie skomplikowany i posiada wiele zasad gramatyki i ortografii (np. polski, niemiecki) bądź posiada budowę zdania inną od tych występujących np. w językach z rodziny indoeuropejskich(takich jak polski, norweski, niemiecki, angielski, grecki, ukraiński etc.). Przykładem języków z inną strukturą gramatyczną niech będą języki np. japoński, koreański, chiński.
Również pod względem kierowania autem nie jest to do końca tak doskonałe, jak niektórzy nam mówią. O ile działa to w przypadkach nieskomplikowanych, dobrze oznakowanych (zarówno poziomo jak i pionowo) dróg tak w przypadku zgiełku bądź wjeżdżania w tzw. “ boczne uliczki” zauważyć można, jak czasami AI szwankuje i np. widzi kosz na śmieci jako samochód bądź przechodnia. Co prawda z dnia na dzień widzimy poprawę, aczkolwiek nie jest to jeszcze poziom jazdy, który możemy uznać za “poprawny” (aczkolwiek jeśli chodzi o wczesne ostrzeganie przed wypadkami działa to zazwyczaj lepiej, niż gdyby miał na takie zdarzenie zareagować kierowca).


Zad 3
Poniższe rodzaje komunikacyjnego zachowania człowieka, jak można zauważyć, zaczęły być coraz częściej zastępowane przez AI.
O ile możemy imitować rozmowy towarzyskie, tak jednak nie oddaje to takiego samego odczucia jak rozmowa z drugim człowiekiem (nawet przez internetowe komunikatory). Po prostu AI często odpowiada nam w sposób nienaturalny dla człowieka, gdyż nie można odczuć żadnych emocji towarzyszących rozmowie przez co czujemy wewnętrznie, że coś jest nie tak i jest to sztucznie generowana rozmowa, jakakolwiek prosta bądź skomplikowana by nie była.
Sztuczna inteligencja często pomija tematy debat politycznych i naukowych, ze względu na to, że nie chce, aby dany użytkownik utożsamiał poglądów dobrze nauczonego modelu jako “prawdy objawionej” (bądź aby nie dopuszczał do siebie poglądów ekstremistycznych). Pozwolenie nawet na imitacje takich debat może prowadzić do opłakanych skutków, takich jak radykalizacja zarówno trenowanego modelu, jak i człowieka, co może się źle skończyć.
Odpowiadanie na pytania klientów na infoliniach jest już zjawiskiem tak częstym i rozpowszechnionym, że możemy powiedzieć, że staje się to (niestety) standardem. Minusem takich imitacji jest to, że system ten jest bardzo słabej jakości i jest mocno podatny na np. zapętlenie się, pogubienie bądź brak sensownej odpowiedzi w przypadku bardziej rozległego problemu.
Zad 4
1. Po wstępnej rozmowie z chatbotami zauważyć można diametralną różnicę. Zazwyczaj bot przystosowany do testu Turinga odpowiada na pytanie w sposób bliski temu, który można zauważyć w rozmowach międzyludzkich. Może opowiedzieć jakąś anegdotę bądź sprawiać wrażenie (nadal sztuczne, przynajmniej w mojej opinii) jakby po drugiej stronie naprawdę występowała prawdziwa osoba. Bot “asystent” (przykład: Siri na urządzeniach Apple) odpowiada w bardzo suchy i szczegółowy sposób. Często przy próbie zainicjowania rozmowy w pewnym momencie nie wie co robić i albo nie przetwarza pytania, albo pokazuje nam wyniki wyszukiwania w internecie dla podanego przez nas zdania, mimo że pewna podstawowa funkcjonalność bycia “chatbotem” jest widoczna (opowiadanie żartów, krótkie, proste rozmowy etc.)
2. Występowanie zachowań:
   1. Żarty - wszystkie przetestowane przeze mnie chatboty miały możliwość opowiadania żartów. 
   2. Przytaczanie cytatów z mojej wypowiedzi lub znanych osób - testowany przeze mnie chatbot poradził sobie z przytoczeniem mojego cytatu bądź znanych osób. Siri nie jest na tyle rozwinięta modelowo do rozmów, więc nie mogłem nawet porozmawiać na tak długo.
   3. Bezbłędnie w przypadku chatbotów, problemy w przypadku asystentów
   4. Chatbot dawał sobie z nim radę, aczkolwiek po czasie tracił lekko wątek główny (testowałem przypadek, w którym miałem pewien problem i rozszerzałem go o dodatkowe informacje). Asystenci odsyłali do wyników wyszukiwania
   5. Mimo że powoli chatbot gubił główny wątek, to nadal radził sobie bardzo nieźle.
   6. Chatbot radził sobie bardzo nieźle do momentu, gdy nie natknąłem się na powtarzające się odpowiedzi mimo zmiany sensu wypowiedzi
   7. Dawał pewne odpowiedzi, aczkolwiek nie były one satysfakcjonujące bądź nie wiedział
   8. Niektóre modele bez problemu sobie z tym poradziły, inne wykazywały troszkę niespójności
   9. Problemy z utrzymaniem wątków pojawiły się przy bardzo długiej rozmowie, na początku wszystko działało jak należy.
3. Moimi głównymi spostrzeżeniami w danych zagadnień było to, jak nienaturalnie dobrze wypada ChatGPT w porównaniu do przykładów danych w pliku pdf. Wykazywał praktycznie zero problemów, nie gubił się, poprawiał błędy jeśli mu to pokazaliśmy oraz był ogólnie “najnaturalniejszy” od np Cleverbota. Asystenci, tacy jak Siri, najczęściej na pytania odpowiadali wynikami wyszukiwania w przeglądarce.
4. Zauważyć można, że chaty w pewnym momencie zaczynają się blokować, a rozmowa prowadzi do nikąd.
5. Zdenerwowanie ChatGPT oraz Siri okazało się niemożliwe, boty nauczone są nie odpowiadać na takie zdarzenia i po prostu odpowiada, że przeprasza i próbuje wszystko co w swojej mocy oraz że nie może okazywać emocji. Cleverbot zaś zaczyna z nami kłótnie, przy czym pyta się nas dlaczego jesteśmy dla niego niemili.